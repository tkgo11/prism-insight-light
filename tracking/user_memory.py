"""
User Memory Manager for Telegram Bot

ì‚¬ìš©ìë³„ ë§¤ë§¤ì¼ì§€ì™€ ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•˜ëŠ” ì§€ì†ì  ê¸°ì–µ ì‹œìŠ¤í…œ.

Features:
- /journal ëª…ë ¹ì–´ë¡œ ë§¤ë§¤ì¼ì§€ ê¸°ë¡
- ë‹¨ê¸°ê¸°ì–µ (1ì£¼ì¼) / ì¥ê¸°ê¸°ì–µ (ê·¸ ì´ìƒ) ë¶„ë¦¬
- /evaluate, /report ëª…ë ¹ì–´ì—ì„œë„ ê¸°ì–µ í™œìš©
- ë‹µì¥ìœ¼ë¡œ ëŒ€í™” ì´ì–´ê°€ê¸° ì§€ì›
- ì‚¬ìš©ìë³„ ê²©ë¦¬ (user_id ê¸°ë°˜)
"""

import json
import logging
import sqlite3
from datetime import datetime, timedelta
from typing import List, Optional, Dict, Any

logger = logging.getLogger(__name__)


class UserMemoryManager:
    """ì‚¬ìš©ìë³„ ê¸°ì–µ ê´€ë¦¬ì"""

    # ê¸°ì–µ íƒ€ì…
    MEMORY_JOURNAL = 'journal'
    MEMORY_EVALUATION = 'evaluation'
    MEMORY_REPORT = 'report'
    MEMORY_CONVERSATION = 'conversation'

    # ì••ì¶• ë ˆì´ì–´ (ê¸°ì¡´ íŒ¨í„´ ë™ì¼)
    LAYER_DETAILED = 1   # 0-7ì¼: ì „ì²´ ë‚´ìš©
    LAYER_SUMMARY = 2    # 8-30ì¼: ìš”ì•½
    LAYER_COMPRESSED = 3  # 31ì¼+: ì••ì¶•

    # í† í° ì˜ˆì‚°
    MAX_CONTEXT_TOKENS = 2000

    def __init__(self, db_path: str):
        """
        UserMemoryManager ì´ˆê¸°í™”

        Args:
            db_path: SQLite ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ
        """
        self.db_path = db_path
        self._ensure_tables()

    def _ensure_tables(self):
        """í…Œì´ë¸” ì¡´ì¬ í™•ì¸ ë° ìƒì„±"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            # user_memories í…Œì´ë¸” ìƒì„±
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS user_memories (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    user_id INTEGER NOT NULL,
                    memory_type TEXT NOT NULL,
                    content TEXT NOT NULL,
                    summary TEXT,
                    ticker TEXT,
                    ticker_name TEXT,
                    market_type TEXT DEFAULT 'kr',
                    importance_score REAL DEFAULT 0.5,
                    compression_layer INTEGER DEFAULT 1,
                    created_at TEXT NOT NULL,
                    last_accessed_at TEXT,
                    command_source TEXT,
                    message_id INTEGER,
                    tags TEXT
                )
            """)

            # user_preferences í…Œì´ë¸” ìƒì„±
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS user_preferences (
                    user_id INTEGER PRIMARY KEY,
                    preferred_tone TEXT DEFAULT 'neutral',
                    investment_style TEXT,
                    favorite_tickers TEXT,
                    total_evaluations INTEGER DEFAULT 0,
                    total_journals INTEGER DEFAULT 0,
                    created_at TEXT NOT NULL,
                    last_active_at TEXT
                )
            """)

            # ì¸ë±ìŠ¤ ìƒì„±
            indexes = [
                "CREATE INDEX IF NOT EXISTS idx_memories_user ON user_memories(user_id)",
                "CREATE INDEX IF NOT EXISTS idx_memories_type ON user_memories(user_id, memory_type)",
                "CREATE INDEX IF NOT EXISTS idx_memories_ticker ON user_memories(user_id, ticker)",
                "CREATE INDEX IF NOT EXISTS idx_memories_created ON user_memories(user_id, created_at DESC)",
            ]
            for idx_sql in indexes:
                cursor.execute(idx_sql)

            conn.commit()
            conn.close()
            logger.info("User memory tables initialized")
        except Exception as e:
            logger.error(f"Failed to initialize user memory tables: {e}")

    def _get_connection(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë°˜í™˜"""
        return sqlite3.connect(self.db_path)

    # =========================================================================
    # í•µì‹¬ ë©”ì„œë“œ
    # =========================================================================

    def save_memory(
        self,
        user_id: int,
        memory_type: str,
        content: Dict[str, Any],
        ticker: Optional[str] = None,
        ticker_name: Optional[str] = None,
        market_type: str = 'kr',
        importance_score: float = 0.5,
        command_source: Optional[str] = None,
        message_id: Optional[int] = None,
        tags: Optional[List[str]] = None
    ) -> int:
        """
        ê¸°ì–µ ì €ì¥

        Args:
            user_id: ì‚¬ìš©ì ID
            memory_type: ê¸°ì–µ íƒ€ì… (journal, evaluation, report, conversation)
            content: ì €ì¥í•  ë‚´ìš© (dict -> JSON)
            ticker: ì¢…ëª© ì½”ë“œ/í‹°ì»¤
            ticker_name: ì¢…ëª©ëª…
            market_type: ì‹œì¥ íƒ€ì… (kr, us)
            importance_score: ì¤‘ìš”ë„ ì ìˆ˜ (0.0 ~ 1.0)
            command_source: ëª…ë ¹ì–´ ì¶œì²˜
            message_id: í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ID
            tags: íƒœê·¸ ë¦¬ìŠ¤íŠ¸

        Returns:
            int: ìƒì„±ëœ ê¸°ì–µ ID
        """
        conn = self._get_connection()
        cursor = conn.cursor()

        try:
            now = datetime.now().isoformat()
            content_json = json.dumps(content, ensure_ascii=False)
            tags_json = json.dumps(tags, ensure_ascii=False) if tags else None

            cursor.execute("""
                INSERT INTO user_memories (
                    user_id, memory_type, content, ticker, ticker_name,
                    market_type, importance_score, compression_layer,
                    created_at, last_accessed_at, command_source, message_id, tags
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                user_id, memory_type, content_json, ticker, ticker_name,
                market_type, importance_score, self.LAYER_DETAILED,
                now, now, command_source, message_id, tags_json
            ))

            memory_id = cursor.lastrowid or 0
            conn.commit()

            # ì‚¬ìš©ì í†µê³„ ì—…ë°ì´íŠ¸
            self._update_user_stats(user_id, memory_type)

            logger.info(f"Memory saved: user={user_id}, type={memory_type}, ticker={ticker}, id={memory_id}")
            return memory_id

        except Exception as e:
            logger.error(f"Failed to save memory: {e}")
            conn.rollback()
            raise
        finally:
            conn.close()

    def get_memories(
        self,
        user_id: int,
        memory_type: Optional[str] = None,
        ticker: Optional[str] = None,
        limit: int = 10,
        include_compressed: bool = True
    ) -> List[Dict[str, Any]]:
        """
        ê¸°ì–µ ì¡°íšŒ

        Args:
            user_id: ì‚¬ìš©ì ID
            memory_type: ê¸°ì–µ íƒ€ì… (Noneì´ë©´ ì „ì²´)
            ticker: ì¢…ëª© ì½”ë“œ/í‹°ì»¤ (Noneì´ë©´ ì „ì²´)
            limit: ìµœëŒ€ ì¡°íšŒ ê°œìˆ˜
            include_compressed: ì••ì¶•ëœ ê¸°ì–µ í¬í•¨ ì—¬ë¶€

        Returns:
            List[Dict]: ê¸°ì–µ ëª©ë¡
        """
        conn = self._get_connection()
        cursor = conn.cursor()

        try:
            query = """
                SELECT id, user_id, memory_type, content, summary, ticker, ticker_name,
                       market_type, importance_score, compression_layer, created_at,
                       last_accessed_at, command_source, message_id, tags
                FROM user_memories
                WHERE user_id = ?
            """
            params: List[Any] = [user_id]

            if memory_type:
                query += " AND memory_type = ?"
                params.append(memory_type)

            if ticker:
                query += " AND ticker = ?"
                params.append(ticker)

            if not include_compressed:
                query += " AND compression_layer < ?"
                params.append(self.LAYER_COMPRESSED)

            query += " ORDER BY created_at DESC LIMIT ?"
            params.append(limit)

            cursor.execute(query, params)
            rows = cursor.fetchall()

            memories = []
            for row in rows:
                memory = {
                    'id': row[0],
                    'user_id': row[1],
                    'memory_type': row[2],
                    'content': json.loads(row[3]) if row[3] else {},
                    'summary': row[4],
                    'ticker': row[5],
                    'ticker_name': row[6],
                    'market_type': row[7],
                    'importance_score': row[8],
                    'compression_layer': row[9],
                    'created_at': row[10],
                    'last_accessed_at': row[11],
                    'command_source': row[12],
                    'message_id': row[13],
                    'tags': json.loads(row[14]) if row[14] else []
                }
                memories.append(memory)

            # ì ‘ê·¼ ì‹œê°„ ì—…ë°ì´íŠ¸
            if memories:
                memory_ids = [m['id'] for m in memories]
                self._update_access_time(memory_ids)

            return memories

        except Exception as e:
            logger.error(f"Failed to get memories: {e}")
            return []
        finally:
            conn.close()

    def build_llm_context(
        self,
        user_id: int,
        ticker: Optional[str] = None,
        max_tokens: int = 2000
    ) -> str:
        """
        LLMì— ì „ë‹¬í•  ê¸°ì–µ ì»¨í…ìŠ¤íŠ¸ ë¹Œë“œ

        Args:
            user_id: ì‚¬ìš©ì ID
            ticker: ì¢…ëª© ì½”ë“œ/í‹°ì»¤ (íŠ¹ì • ì¢…ëª©ì— ëŒ€í•œ ê¸°ì–µ ìš°ì„ )
            max_tokens: ìµœëŒ€ í† í° ìˆ˜

        Returns:
            str: í¬ë§·íŒ…ëœ ê¸°ì–µ ì»¨í…ìŠ¤íŠ¸
        """
        parts = []
        tokens = 0

        # í† í° ì¶”ì • í•¨ìˆ˜ (í•œê¸€ ê¸°ì¤€ ëŒ€ëµì  ì¶”ì •)
        def estimate_tokens(text: str) -> int:
            return len(text) // 2  # í•œê¸€ì€ ëŒ€ëµ 2ê¸€ìë‹¹ 1í† í°

        # ìš°ì„ ìˆœìœ„ 1: í•´ë‹¹ ì¢…ëª© ì €ë„ (ìµœëŒ€ 800 í† í°)
        if ticker:
            journals = self.get_journals(user_id, ticker=ticker, limit=5)
            if journals:
                journal_text = self._format_journals(journals)
                journal_tokens = estimate_tokens(journal_text)
                if journal_tokens < 800:
                    parts.append(f"ğŸ“ {ticker} ê´€ë ¨ ê¸°ë¡:\n{journal_text}")
                    tokens += journal_tokens

        # ìš°ì„ ìˆœìœ„ 2: í•´ë‹¹ ì¢…ëª© ê³¼ê±° í‰ê°€ (ìµœëŒ€ 500 í† í°)
        if ticker and tokens < max_tokens - 500:
            evals = self.get_memories(user_id, self.MEMORY_EVALUATION, ticker=ticker, limit=3)
            if evals:
                eval_text = self._format_evaluations(evals)
                eval_tokens = estimate_tokens(eval_text)
                if tokens + eval_tokens < max_tokens:
                    parts.append(f"ğŸ“Š ê³¼ê±° í‰ê°€:\n{eval_text}")
                    tokens += eval_tokens

        # ìš°ì„ ìˆœìœ„ 3: ìµœê·¼ ì¼ë°˜ ì €ë„ (ë‚¨ì€ í† í°)
        if tokens < max_tokens - 300:
            recent = self.get_journals(user_id, limit=3)
            # ì´ë¯¸ í¬í•¨ëœ ticker ì œì™¸
            recent = [j for j in recent if j.get('ticker') != ticker]
            if recent:
                recent_text = self._format_journals(recent)
                recent_tokens = estimate_tokens(recent_text)
                if tokens + recent_tokens < max_tokens:
                    parts.append(f"ğŸ’­ ìµœê·¼ ìƒê°:\n{recent_text}")

        return "\n\n".join(parts) if parts else ""

    # =========================================================================
    # ì €ë„ ì „ìš© ë©”ì„œë“œ
    # =========================================================================

    def save_journal(
        self,
        user_id: int,
        text: str,
        ticker: Optional[str] = None,
        ticker_name: Optional[str] = None,
        market_type: str = 'kr',
        message_id: Optional[int] = None
    ) -> int:
        """
        ì €ë„(íˆ¬ì ì¼ê¸°) ì €ì¥

        Args:
            user_id: ì‚¬ìš©ì ID
            text: ì €ë„ í…ìŠ¤íŠ¸
            ticker: ì¢…ëª© ì½”ë“œ/í‹°ì»¤
            ticker_name: ì¢…ëª©ëª…
            market_type: ì‹œì¥ íƒ€ì…
            message_id: í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ID

        Returns:
            int: ìƒì„±ëœ ê¸°ì–µ ID
        """
        content = {
            'text': text,
            'raw_input': text,
            'recorded_at': datetime.now().isoformat()
        }

        return self.save_memory(
            user_id=user_id,
            memory_type=self.MEMORY_JOURNAL,
            content=content,
            ticker=ticker,
            ticker_name=ticker_name,
            market_type=market_type,
            importance_score=0.7,  # ì €ë„ì€ ê¸°ë³¸ì ìœ¼ë¡œ ì¤‘ìš”ë„ ë†’ìŒ
            command_source='/journal',
            message_id=message_id
        )

    def get_journals(
        self,
        user_id: int,
        ticker: Optional[str] = None,
        limit: int = 5
    ) -> List[Dict[str, Any]]:
        """
        ì €ë„ ì¡°íšŒ

        Args:
            user_id: ì‚¬ìš©ì ID
            ticker: ì¢…ëª© ì½”ë“œ/í‹°ì»¤
            limit: ìµœëŒ€ ì¡°íšŒ ê°œìˆ˜

        Returns:
            List[Dict]: ì €ë„ ëª©ë¡
        """
        return self.get_memories(
            user_id=user_id,
            memory_type=self.MEMORY_JOURNAL,
            ticker=ticker,
            limit=limit
        )

    # =========================================================================
    # ì••ì¶• ë©”ì„œë“œ
    # =========================================================================

    def compress_old_memories(
        self,
        layer1_days: int = 7,
        layer2_days: int = 30
    ) -> Dict[str, int]:
        """
        ì˜¤ë˜ëœ ê¸°ì–µ ì••ì¶• (ì•¼ê°„ ë°°ì¹˜ìš©)

        Args:
            layer1_days: Layer 1 -> Layer 2 ì „í™˜ ê¸°ì¤€ì¼ (ê¸°ë³¸ 7ì¼)
            layer2_days: Layer 2 -> Layer 3 ì „í™˜ ê¸°ì¤€ì¼ (ê¸°ë³¸ 30ì¼)

        Returns:
            Dict[str, int]: ì••ì¶• í†µê³„ {'layer2_count': n, 'layer3_count': n}
        """
        conn = self._get_connection()
        cursor = conn.cursor()

        stats = {'layer2_count': 0, 'layer3_count': 0}

        try:
            now = datetime.now()
            layer2_cutoff = (now - timedelta(days=layer1_days)).isoformat()
            layer3_cutoff = (now - timedelta(days=layer2_days)).isoformat()

            # Layer 1 -> Layer 2 (7ì¼ ì´ìƒ)
            cursor.execute("""
                SELECT id, content, ticker, ticker_name
                FROM user_memories
                WHERE compression_layer = 1
                AND created_at < ?
            """, (layer2_cutoff,))

            for row in cursor.fetchall():
                memory_id, content_json, ticker, ticker_name = row
                content = json.loads(content_json) if content_json else {}

                # ìš”ì•½ ìƒì„±
                summary = self._generate_summary(content, ticker, ticker_name)

                cursor.execute("""
                    UPDATE user_memories
                    SET compression_layer = 2, summary = ?
                    WHERE id = ?
                """, (summary, memory_id))
                stats['layer2_count'] += 1

            # Layer 2 -> Layer 3 (30ì¼ ì´ìƒ)
            cursor.execute("""
                SELECT id, summary, ticker, ticker_name
                FROM user_memories
                WHERE compression_layer = 2
                AND created_at < ?
            """, (layer3_cutoff,))

            for row in cursor.fetchall():
                memory_id, summary, ticker, ticker_name = row

                # í•œì¤„ ì••ì¶• ìƒì„±
                compressed = self._generate_compressed(summary, ticker, ticker_name)

                cursor.execute("""
                    UPDATE user_memories
                    SET compression_layer = 3, summary = ?
                    WHERE id = ?
                """, (compressed, memory_id))
                stats['layer3_count'] += 1

            conn.commit()
            logger.info(f"Memory compression completed: {stats}")
            return stats

        except Exception as e:
            logger.error(f"Failed to compress memories: {e}")
            conn.rollback()
            return stats
        finally:
            conn.close()

    # =========================================================================
    # ì‚¬ìš©ì ì„ í˜¸ ë©”ì„œë“œ
    # =========================================================================

    def get_user_preferences(self, user_id: int) -> Optional[Dict[str, Any]]:
        """ì‚¬ìš©ì ì„ í˜¸ ì„¤ì • ì¡°íšŒ"""
        conn = self._get_connection()
        cursor = conn.cursor()

        try:
            cursor.execute("""
                SELECT user_id, preferred_tone, investment_style, favorite_tickers,
                       total_evaluations, total_journals, created_at, last_active_at
                FROM user_preferences
                WHERE user_id = ?
            """, (user_id,))

            row = cursor.fetchone()
            if row:
                return {
                    'user_id': row[0],
                    'preferred_tone': row[1],
                    'investment_style': row[2],
                    'favorite_tickers': json.loads(row[3]) if row[3] else [],
                    'total_evaluations': row[4],
                    'total_journals': row[5],
                    'created_at': row[6],
                    'last_active_at': row[7]
                }
            return None
        except Exception as e:
            logger.error(f"Failed to get user preferences: {e}")
            return None
        finally:
            conn.close()

    def update_user_preferences(
        self,
        user_id: int,
        preferred_tone: Optional[str] = None,
        investment_style: Optional[str] = None,
        favorite_tickers: Optional[List[str]] = None
    ):
        """ì‚¬ìš©ì ì„ í˜¸ ì„¤ì • ì—…ë°ì´íŠ¸"""
        conn = self._get_connection()
        cursor = conn.cursor()

        try:
            now = datetime.now().isoformat()

            # ê¸°ì¡´ ì„¤ì • í™•ì¸
            cursor.execute("SELECT user_id FROM user_preferences WHERE user_id = ?", (user_id,))
            exists = cursor.fetchone() is not None

            if exists:
                updates = []
                params = []

                if preferred_tone is not None:
                    updates.append("preferred_tone = ?")
                    params.append(preferred_tone)

                if investment_style is not None:
                    updates.append("investment_style = ?")
                    params.append(investment_style)

                if favorite_tickers is not None:
                    updates.append("favorite_tickers = ?")
                    params.append(json.dumps(favorite_tickers, ensure_ascii=False))

                updates.append("last_active_at = ?")
                params.append(now)
                params.append(user_id)

                if updates:
                    cursor.execute(f"""
                        UPDATE user_preferences
                        SET {', '.join(updates)}
                        WHERE user_id = ?
                    """, params)
            else:
                favorite_json = json.dumps(favorite_tickers, ensure_ascii=False) if favorite_tickers else None
                cursor.execute("""
                    INSERT INTO user_preferences (
                        user_id, preferred_tone, investment_style, favorite_tickers,
                        total_evaluations, total_journals, created_at, last_active_at
                    ) VALUES (?, ?, ?, ?, 0, 0, ?, ?)
                """, (user_id, preferred_tone, investment_style, favorite_json, now, now))

            conn.commit()
        except Exception as e:
            logger.error(f"Failed to update user preferences: {e}")
            conn.rollback()
        finally:
            conn.close()

    # =========================================================================
    # Private í—¬í¼ ë©”ì„œë“œ
    # =========================================================================

    def _update_user_stats(self, user_id: int, memory_type: str):
        """ì‚¬ìš©ì í†µê³„ ì—…ë°ì´íŠ¸"""
        conn = self._get_connection()
        cursor = conn.cursor()

        try:
            now = datetime.now().isoformat()

            # ê¸°ì¡´ ì„¤ì • í™•ì¸
            cursor.execute("SELECT user_id FROM user_preferences WHERE user_id = ?", (user_id,))
            exists = cursor.fetchone() is not None

            if exists:
                if memory_type == self.MEMORY_JOURNAL:
                    cursor.execute("""
                        UPDATE user_preferences
                        SET total_journals = total_journals + 1, last_active_at = ?
                        WHERE user_id = ?
                    """, (now, user_id))
                elif memory_type == self.MEMORY_EVALUATION:
                    cursor.execute("""
                        UPDATE user_preferences
                        SET total_evaluations = total_evaluations + 1, last_active_at = ?
                        WHERE user_id = ?
                    """, (now, user_id))
                else:
                    cursor.execute("""
                        UPDATE user_preferences
                        SET last_active_at = ?
                        WHERE user_id = ?
                    """, (now, user_id))
            else:
                journals = 1 if memory_type == self.MEMORY_JOURNAL else 0
                evals = 1 if memory_type == self.MEMORY_EVALUATION else 0
                cursor.execute("""
                    INSERT INTO user_preferences (
                        user_id, total_evaluations, total_journals, created_at, last_active_at
                    ) VALUES (?, ?, ?, ?, ?)
                """, (user_id, evals, journals, now, now))

            conn.commit()
        except Exception as e:
            logger.error(f"Failed to update user stats: {e}")
        finally:
            conn.close()

    def _update_access_time(self, memory_ids: List[int]):
        """ê¸°ì–µ ì ‘ê·¼ ì‹œê°„ ì—…ë°ì´íŠ¸"""
        if not memory_ids:
            return

        conn = self._get_connection()
        cursor = conn.cursor()

        try:
            now = datetime.now().isoformat()
            placeholders = ','.join(['?' for _ in memory_ids])
            cursor.execute(f"""
                UPDATE user_memories
                SET last_accessed_at = ?
                WHERE id IN ({placeholders})
            """, [now] + memory_ids)
            conn.commit()
        except Exception as e:
            logger.error(f"Failed to update access time: {e}")
        finally:
            conn.close()

    def _format_journals(self, journals: List[Dict[str, Any]]) -> str:
        """ì €ë„ì„ í¬ë§·íŒ… (ìƒì„¸ ë‚´ìš© í¬í•¨)"""
        lines = []
        for j in journals:
            created = j.get('created_at', '')[:10]
            content = j.get('content', {})
            text = content.get('text', '')[:500]  # 500ìë¡œ í™•ì¥ (ê¸°ì¡´ 100ì)
            ticker = j.get('ticker', '')
            ticker_name = j.get('ticker_name', '')

            # í‹°ì»¤ì™€ ì¢…ëª©ëª… í•¨ê»˜ í‘œì‹œ
            if ticker and ticker_name:
                lines.append(f"- [{created}] {ticker_name}({ticker}): {text}")
            elif ticker:
                lines.append(f"- [{created}] ({ticker}): {text}")
            else:
                lines.append(f"- [{created}] {text}")

        return '\n'.join(lines)

    def _format_evaluations(self, evals: List[Dict[str, Any]]) -> str:
        """í‰ê°€ë¥¼ í¬ë§·íŒ… (ìƒì„¸ ë‚´ìš© í¬í•¨)"""
        lines = []
        for e in evals:
            created = e.get('created_at', '')[:10]
            content = e.get('content', {})

            # ìš”ì•½ì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ì‘ë‹µì—ì„œ ì¶”ì¶œ
            summary = e.get('summary')
            if not summary:
                response = content.get('response_summary', '')
                summary = response[:300] + '...' if len(response) > 300 else response  # 300ìë¡œ í™•ì¥

            ticker = e.get('ticker', '')
            ticker_name = e.get('ticker_name', '')
            if ticker_name:
                lines.append(f"- [{created}] {ticker_name}({ticker}): {summary}")
            else:
                lines.append(f"- [{created}] {ticker}: {summary}")

        return '\n'.join(lines)

    def _generate_summary(
        self,
        content: Dict[str, Any],
        ticker: Optional[str],
        ticker_name: Optional[str]
    ) -> str:
        """ê¸°ì–µ ìš”ì•½ ìƒì„± (Layer 2ìš©)"""
        text = content.get('text', content.get('response_summary', ''))
        if not text:
            return ''

        # ê°„ë‹¨í•œ ìš”ì•½ ìƒì„± (LLM ì—†ì´ ê·œì¹™ ê¸°ë°˜)
        # ì‹¤ì œë¡œëŠ” LLMì„ ì‚¬ìš©í•  ìˆ˜ ìˆì§€ë§Œ, ë¹„ìš© ì ˆê°ì„ ìœ„í•´ ê·œì¹™ ê¸°ë°˜ ì‚¬ìš©
        ticker_prefix = f"{ticker}: " if ticker else ""
        summary = text[:150].replace('\n', ' ').strip()

        return f"{ticker_prefix}{summary}"

    def _generate_compressed(
        self,
        summary: Optional[str],
        ticker: Optional[str],
        ticker_name: Optional[str]
    ) -> str:
        """í•œì¤„ ì••ì¶• ìƒì„± (Layer 3ìš©)"""
        if not summary:
            return ''

        # í•œì¤„ ì••ì¶• (ìµœëŒ€ 50ì)
        ticker_prefix = f"{ticker} " if ticker else ""
        compressed = summary[:50].replace('\n', ' ').strip()

        return f"{ticker_prefix}{compressed}"

    def delete_memory(self, memory_id: int, user_id: int) -> bool:
        """
        íŠ¹ì • ê¸°ì–µ ì‚­ì œ (ì‚¬ìš©ì ì†Œìœ  í™•ì¸)

        Args:
            memory_id: ê¸°ì–µ ID
            user_id: ì‚¬ìš©ì ID (ì†Œìœ ì í™•ì¸ìš©)

        Returns:
            bool: ì‚­ì œ ì„±ê³µ ì—¬ë¶€
        """
        conn = self._get_connection()
        cursor = conn.cursor()

        try:
            cursor.execute("""
                DELETE FROM user_memories
                WHERE id = ? AND user_id = ?
            """, (memory_id, user_id))
            conn.commit()
            return cursor.rowcount > 0
        except Exception as e:
            logger.error(f"Failed to delete memory: {e}")
            return False
        finally:
            conn.close()

    def get_memory_stats(self, user_id: int) -> Dict[str, Any]:
        """ì‚¬ìš©ì ê¸°ì–µ í†µê³„ ì¡°íšŒ"""
        conn = self._get_connection()
        cursor = conn.cursor()

        try:
            # íƒ€ì…ë³„ ê°œìˆ˜
            cursor.execute("""
                SELECT memory_type, COUNT(*) as count
                FROM user_memories
                WHERE user_id = ?
                GROUP BY memory_type
            """, (user_id,))
            type_counts = {row[0]: row[1] for row in cursor.fetchall()}

            # ì••ì¶• ë ˆì´ì–´ë³„ ê°œìˆ˜
            cursor.execute("""
                SELECT compression_layer, COUNT(*) as count
                FROM user_memories
                WHERE user_id = ?
                GROUP BY compression_layer
            """, (user_id,))
            layer_counts = {f"layer_{row[0]}": row[1] for row in cursor.fetchall()}

            # ì¢…ëª©ë³„ ê°œìˆ˜
            cursor.execute("""
                SELECT ticker, COUNT(*) as count
                FROM user_memories
                WHERE user_id = ? AND ticker IS NOT NULL
                GROUP BY ticker
                ORDER BY count DESC
                LIMIT 10
            """, (user_id,))
            ticker_counts = {row[0]: row[1] for row in cursor.fetchall()}

            return {
                'by_type': type_counts,
                'by_layer': layer_counts,
                'by_ticker': ticker_counts,
                'total': sum(type_counts.values())
            }
        except Exception as e:
            logger.error(f"Failed to get memory stats: {e}")
            return {}
        finally:
            conn.close()
